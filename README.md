# Image-caption-generator
This project focuses on generating meaningful textual descriptions (captions) for input images using a deep learning architecture that combines VGG16 for image feature extraction and LSTM for caption generation. The model is trained on the Flickr8K dataset, which contains over 8,000 images each annotated with multiple human-written captions.
